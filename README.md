
# Text Classifier v2: AI vs SLW (Second Language Writers)

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)  
[![Streamlit](https://img.shields.io/badge/Built%20with-Streamlit-ff4b4b)](https://streamlit.io/)  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This project is an extension of [Text Classifier v1](https://github.com/Risang-L/text-classifier), using a stronger **XGBoost model** and larger dataset. It explores linguistic data science and syntactic complexity modeling.

[Live App](https://text-classifier-cgjwc5d4nmgp8afaxdcuzsie.streamlit.app/)

---

## Table of Contents

- [Features](#features)  
- [About the syntactic Complexity Indices](#about-the-syntactic-complexity-indices)  
- [Data Overview](#data-overview)  
- [Improvements over v1](#improvements-over-v1)  
- [Acknowledgements](#acknowledgements)  

---

## Features

- Load real-world `.txt` samples by index  
- Visualize syntactic complexity indices (e.g., MLS, CN_C, VP_T)  
- Generate classification results with confidence scores  
- Explore SHAP waterfall plots to interpret predictions  

---

## About the syntactic Complexity Indices

The classifier uses L2SCA indices by [TAASSC](https://www.linguisticanalyistools.org/taassc.html).

Predictions are supported by SHAP contribution plots, showing how each feature influences the outcome toward AI or SLW.

---

## Data Overview

The dataset consists of **1,000+ writing samples** divided into two categories:

- **Human-written**:  
    500 essays by second language writers (SLW), sourced from [ICNALE](https://language.sakura.ne.jp/icnale/)  
- **AI-generated**:  
    500 essays generated by large language models (LLMs), sourced from [LLM-generated Essay Dataset](https://huggingface.co/datasets/dshihk/llm-generated-essay)  

Data preprocessing by TAASSC.

---

## Improvements over v1

- Upgraded from Random Forest to **XGBoost**
- Doubled dataset size (from 300 â†’ 1000+ samples)
- More stable predictions and improved feature interpretability  

---

## Acknowledgements

Thanks to ICNALE, TAASSC, Hugging Face dataset contributors, and open-source NLP communities.

---
